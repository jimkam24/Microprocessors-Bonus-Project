{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1_ZSEu4THNmmKHXn7WmFdjjkzZ5M9_ixg","timestamp":1739490106696}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Necessary imports"],"metadata":{"id":"zmojdTjnnKD9"}},{"cell_type":"code","source":["!pip install tensorflow-model-optimization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VEkj768D3uhR","executionInfo":{"status":"ok","timestamp":1740387384857,"user_tz":-120,"elapsed":9889,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}},"outputId":"7aecbbbf-7c5d-4a4c-b73f-fe210def9a89"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-model-optimization\n","  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n","Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.4.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\n","Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.26.4)\n","Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\n","Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.1.0)\n","Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.17.2)\n","Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorflow-model-optimization\n","Successfully installed tensorflow-model-optimization-0.8.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-G2EiFI_nFkI","executionInfo":{"status":"ok","timestamp":1740387404976,"user_tz":-120,"elapsed":20116,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"outputs":[],"source":["import os\n","import tensorflow as tf\n","import tensorflow_model_optimization as tfmot"]},{"cell_type":"code","source":["# function to create lenet model\n","def build_lenet5_mnist():\n","\n","\n","    model = tf.keras.Sequential([\n","\n","        # 4 layers -> 2 convolutional and 2 pooling\n","        tf.keras.layers.Conv2D(6, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu', input_shape = (28, 28, 1)),\n","        tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2),\n","\n","        tf.keras.layers.Conv2D(16, kernel_size = 5, strides = 1, activation = 'relu'),\n","        tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2),\n","\n","        # 2D -> 1D\n","        tf.keras.layers.Flatten(),\n","\n","        # 3 fully connected layers\n","        tf.keras.layers.Dense(120, activation = 'relu'),\n","        tf.keras.layers.Dense(84, activation = 'relu'),\n","        tf.keras.layers.Dense(10, activation = 'softmax')\n","    ])\n","\n","    return model"],"metadata":{"id":"KG-iYCZFnP8Z","executionInfo":{"status":"ok","timestamp":1740387404978,"user_tz":-120,"elapsed":4,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Define a pruning schedule\n","def build_lenet5_mnist_with_pruning():\n","    # Define pruning schedule (starts pruning at 0% and increases to 50% pruning over 10 epochs)\n","    pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n","        initial_sparsity=0.0,  # Start with no pruning\n","        final_sparsity=0.5,    # End with 50% sparsity\n","        begin_step=0,          # Start pruning from the beginning\n","        end_step=2000          # End pruning after 2000 steps\n","    )\n","\n","    # Build model with pruning\n","    model = tf.keras.Sequential([\n","        tfmot.sparsity.keras.prune_low_magnitude(  # Apply pruning to this layer\n","            tf.keras.layers.Conv2D(6, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n","            pruning_schedule\n","        ),\n","        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n","\n","        tfmot.sparsity.keras.prune_low_magnitude(  # Apply pruning to this layer\n","            tf.keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='relu'),\n","            pruning_schedule\n","        ),\n","        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n","\n","        # Flatten layer (no pruning here)\n","        tf.keras.layers.Flatten(),\n","\n","        tfmot.sparsity.keras.prune_low_magnitude(  # Apply pruning to this layer\n","            tf.keras.layers.Dense(120, activation='relu'),\n","            pruning_schedule\n","        ),\n","        tfmot.sparsity.keras.prune_low_magnitude(  # Apply pruning to this layer\n","            tf.keras.layers.Dense(84, activation='relu'),\n","            pruning_schedule\n","        ),\n","        tf.keras.layers.Dense(10, activation='softmax')  # No pruning here\n","    ])\n","\n","    return model\n"],"metadata":{"id":"G_0dqUHy3X3g","executionInfo":{"status":"ok","timestamp":1740387405041,"user_tz":-120,"elapsed":47,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# function to load MNIST dataset and do some preprocessing\n","def load_data(validation_split = 0.25):\n","    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","    # Normalization can reduce training time significantly and (usually) increases the model's accuracy\n","    x_train = x_train.astype('float32') / 255.0\n","    x_test = x_test.astype('float32') / 255.0\n","\n","    # expand dimensions from (28, 28) to (28, 28, 1) to match the input format of the first convolutional layer of the model\n","    x_train = x_train[..., tf.newaxis]\n","    x_test = x_test[..., tf.newaxis]\n","\n","    # Make sure that your labels are in numerical form\n","    y_train = tf.keras.utils.to_categorical(y_train, 10)\n","    y_test = tf.keras.utils.to_categorical(y_test, 10)\n","\n","    # A subset of the dataset can be used in order to monitor how our network behaves during training\n","    # (validation dataset) and helps us avoid overfitting the model to the training dataset.\n","    # The network's parameters are not updated when examining this subset of data\n","\n","    # create validation dataset\n","    if validation_split is not None:\n","        num_validation_samples = int(validation_split * x_train.shape[0])\n","        x_train, x_val = x_train[:-num_validation_samples], x_train[-num_validation_samples:]\n","        y_train, y_val = y_train[:-num_validation_samples], y_train[-num_validation_samples:]\n","        return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n","\n","    else:\n","        return (x_train, y_train), (x_test, y_test), (x_test, y_test)"],"metadata":{"id":"m0p62a1Zpibz","executionInfo":{"status":"ok","timestamp":1740387405091,"user_tz":-120,"elapsed":48,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# function to train the model\n","def train_model(model, X_train, y_train, X_val, y_val, epochs = 25, learning_rate = 0.001,\n","                patience = 5, batch_size = 32):\n","\n","    # You can experiment with different optimizers and learning rates (no need to focus on that though !!!)\n","    model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = learning_rate, momentum = 0.9),\n","                  loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","\n","    # Apply early stopping to speed up training and avoid overfitting (very helpful with smaller datasets)\n","    # In this instance, if the validation loss does not drop over 0.001 for <patience> number of epochs,\n","    # the training stops.\n","\n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = patience,\n","                                   min_delta = 0.001, restore_best_weights = True)\n","\n","    # Train the model\n","    model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size,\n","              validation_data = (X_val, y_val),\n","              callbacks = [early_stopping])\n","\n","    return model"],"metadata":{"id":"pApUGVgUqIvg","executionInfo":{"status":"ok","timestamp":1740387405187,"user_tz":-120,"elapsed":88,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def train_prune_model(model, X_train, y_train, X_val, y_val, epochs = 25, learning_rate = 0.001, patience = 5, batch_size = 32):\n","  # Compile model with pruning\n","  model = build_lenet5_mnist_with_pruning()\n","  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","  # Model summary to view the layers with pruning applied\n","  model.summary()\n","\n","  # Training model\n","  # You should use a callback to ensure the pruning process is applied during training\n","  pruning_callbacks = [\n","      tfmot.sparsity.keras.UpdatePruningStep()  # Callback to update pruning during training\n","  ]\n","\n","  # Train model (pruning will be applied during training)\n","  model.fit(X_train, y_train, epochs=epochs, batch_size = batch_size, validation_data=(X_val, y_val), callbacks=pruning_callbacks)"],"metadata":{"id":"-olOyYbd4Brv","executionInfo":{"status":"ok","timestamp":1740387405193,"user_tz":-120,"elapsed":2,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"g1izn1Ms3Huc"}},{"cell_type":"code","source":["# function to evaluate the accuracy of the trained model\n","def evaluate_model(model, X_test, y_test):\n","    _, test_accuracy = model.evaluate(X_test, y_test)\n","    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n","    return test_accuracy * 100"],"metadata":{"id":"byhIb8rgrR-5","executionInfo":{"status":"ok","timestamp":1740387405204,"user_tz":-120,"elapsed":2,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# function to provide a small dataset sample for integer quantization\n","def representative_dataset():\n","    \"\"\"\"\n","    Representative dataset for integer quantization (calibration data to scale the\n","    weights and inputs to the integer domain)\n","    \"\"\"\n","    for i in range(100):\n","        yield [X_train[i:i+1].astype('float32')]"],"metadata":{"id":"za0psVTlrlqt","executionInfo":{"status":"ok","timestamp":1740387405209,"user_tz":-120,"elapsed":3,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# function to cnvert the model to TFLite format (to use in our device)\n","def convert_to_tflite(model, filename = \"model.tflite\"):\n","    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","    tflite_model = converter.convert()\n","    with open(filename, \"wb\") as f:\n","        f.write(tflite_model)\n","    print(f\"Model converted to TFLite and saved as {filename}\")\n","\n","    model_size = os.path.getsize(filename) / 1024  # Size in KB\n","    print(f\"TFLite Model Size: {model_size:.2f} KB\")\n","\n","    return filename\n"],"metadata":{"id":"PYZU3ijzsU3a","executionInfo":{"status":"ok","timestamp":1740387405252,"user_tz":-120,"elapsed":33,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# function to convert the model to a quantized TFLite version (reduced model size and better efficiency)\n","def convert_to_quantized_tflite(model, filename = \"model.tflite\"):\n","    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","\n","    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","    converter.representative_dataset = representative_dataset\n","    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","    converter.inference_input_type = tf.uint8\n","    converter.inference_output_type = tf.uint8\n","\n","    tflite_model = converter.convert()\n","\n","    with open(filename, \"wb\") as f:\n","        f.write(tflite_model)\n","\n","    print(f\"Quantized model converted to TFLite and saved as {filename}\")\n","\n","    # Calculate and print the size of the TFLite model\n","    model_size = os.path.getsize(filename) / 1024  # Size in KB\n","    print(f\"Quantized TFLite Model Size: {model_size:.2f} KB\")\n","\n","    return filename"],"metadata":{"id":"aRXDF7hdslmE","executionInfo":{"status":"ok","timestamp":1740387405313,"user_tz":-120,"elapsed":4,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# function to perform inference for a tflite model\n","def tflite_inference(tflite_model_path, X_test, y_test):\n","    \"\"\"\n","    Perform inference using a TFLite model. This function can be used\n","    in order to evaluate the performance of your models after applying your\n","    optimization techniques (i.e. Quantization, pruning etc).\n","    \"\"\"\n","\n","    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n","    interpreter.allocate_tensors()\n","\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    # In case we quantized our model to Full integer format, we need to be careful and\n","    # check if the input type is UINT8 --> if so, we must normalize data to the\n","    # quantized range [1]\n","\n","    input_dtype = input_details[0]['dtype']\n","    print(input_dtype)\n","\n","    # [1]\n","    if input_dtype == tf.uint8:\n","        scale, zero_point = input_details[0]['quantization']\n","        X_test = (X_test / scale + zero_point).astype(input_dtype)\n","\n","    # iterate over predictions and store results\n","    predictions = []\n","    for i in range(X_test.shape[0]):\n","        input_data = X_test[i:i+1]\n","        interpreter.set_tensor(input_details[0]['index'], input_data)\n","        interpreter.invoke()\n","        output_data = interpreter.get_tensor(output_details[0]['index'])\n","        predictions.append(output_data)\n","\n","    # iterate over predictions to find correct ones\n","    correct = 0\n","    for i, prediction in enumerate(predictions):\n","        predicted_label = tf.argmax(prediction[0]).numpy()\n","        true_label = tf.argmax(y_test[i]).numpy()\n","        if predicted_label == true_label:\n","            correct += 1\n","\n","    # print the accuracy of our model\n","    accuracy = correct / len(X_test) * 100\n","    print(f\"TFLite Model Accuracy: {accuracy:.2f}%\")\n","    return accuracy"],"metadata":{"id":"BOlwle93tfSv","executionInfo":{"status":"ok","timestamp":1740387405319,"user_tz":-120,"elapsed":4,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Specify device (CPU or GPU)\n","device_name = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n","print(f\"Training on: {device_name}\")\n","\n","with tf.device(device_name):\n","\n","    # lenet model\n","    model = build_lenet5_mnist()\n","    model.summary()\n","\n","    epochs = [1, 1]\n","    learning_rate = [0.001, 0.0005]\n","    BATCH_SZ = 32\n","    patience = 3\n","\n","    # load mnist\n","    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_data()\n","\n","    # perform training\n","    for i, (e, lr) in enumerate(zip(epochs, learning_rate)):\n","        print(f\"\\nStarting training iteration {i + 1} with {e} epochs and learning rate {lr}\")\n","        model = train_model(model, X_train, y_train, X_val, y_val, e, lr, patience, BATCH_SZ)\n","\n","    print(\"\\n\\nFinal Evaluation on Test Data:\")\n","    initial_model_accuracy = evaluate_model(model, X_test, y_test)\n","\n","    ########## Let's convert the model to TFLITE FORMAT ###########\n","    tflite_model_path = convert_to_tflite(model)\n","\n","    # Without applying any optimizations to our model, the accuracy should remain the same ...\n","    print(\"\\n\\nPerforming inference with TFLite model...\")\n","    tflite_no_opt_accuracy = tflite_inference(tflite_model_path, X_test, y_test)\n","\n","    ##### QUANTIZATION #####\n","\n","    integer_tflite_path = convert_to_quantized_tflite(model, filename = \"quantized_model.tflite\")\n","\n","    print(f\"\\nInference with Integer quantization...\")\n","    tflite_int_quant_acc = tflite_inference(integer_tflite_path, X_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_x7MBLoAubSv","outputId":"7446b8ba-8bd2-45d1-ebed-980b98d7d513","executionInfo":{"status":"ok","timestamp":1740387506777,"user_tz":-120,"elapsed":101459,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on: /CPU:0\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 28, 28, 6)         156       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 14, 14, 6)         0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 5, 5, 16)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 400)               0         \n","                                                                 \n"," dense (Dense)               (None, 120)               48120     \n","                                                                 \n"," dense_1 (Dense)             (None, 84)                10164     \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                850       \n","                                                                 \n","=================================================================\n","Total params: 61706 (241.04 KB)\n","Trainable params: 61706 (241.04 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","\n","Starting training iteration 1 with 1 epochs and learning rate 0.001\n","1407/1407 [==============================] - 47s 32ms/step - loss: 0.6732 - accuracy: 0.7923 - val_loss: 0.1855 - val_accuracy: 0.9429\n","\n","Starting training iteration 2 with 1 epochs and learning rate 0.0005\n","1407/1407 [==============================] - 33s 23ms/step - loss: 0.1578 - accuracy: 0.9521 - val_loss: 0.1421 - val_accuracy: 0.9582\n","\n","\n","Final Evaluation on Test Data:\n","313/313 [==============================] - 2s 8ms/step - loss: 0.1213 - accuracy: 0.9615\n","Test Accuracy: 96.15%\n","Model converted to TFLite and saved as model.tflite\n","TFLite Model Size: 244.69 KB\n","\n","\n","Performing inference with TFLite model...\n","<class 'numpy.float32'>\n","TFLite Model Accuracy: 96.15%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Quantized model converted to TFLite and saved as quantized_model.tflite\n","Quantized TFLite Model Size: 71.05 KB\n","\n","Inference with Integer quantization...\n","<class 'numpy.uint8'>\n","TFLite Model Accuracy: 96.11%\n"]}]},{"cell_type":"code","source":["def load_mnist(i = 0):\n","    # Load MNIST dataset\n","    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","\n","    # Normalize the images to be between 0 and 1\n","    # comment below for the quantized\n","    # train_images = train_images.astype('float32') / 255.0\n","    # test_images = test_images.astype('float32') / 255.0\n","\n","    # Reshape the images to add the channel dimension (28, 28, 1)\n","    train_images = np.expand_dims(train_images, axis=-1)  # (28, 28, 1)\n","    test_images = np.expand_dims(test_images, axis=-1)  # (28, 28, 1)\n","\n","    # Return a single image with the batch dimension (1, 28, 28, 1)\n","    # Adding the batch dimension for a single image from the test set\n","    return np.expand_dims(test_images[i], axis=0), test_labels[i]  # Shape will be (1, 28, 28, 1)"],"metadata":{"id":"MXGV7AT9LUBW","executionInfo":{"status":"ok","timestamp":1740387506796,"user_tz":-120,"elapsed":18,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np"],"metadata":{"id":"-TT8B5qxsYzd","executionInfo":{"status":"ok","timestamp":1740387506798,"user_tz":-120,"elapsed":1,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#QUANTIZED gia ena input\n","import time\n","import numpy as np\n","import tensorflow as tf\n","\n","# Load the TFLite model\n","tflite_model_path = 'quantized_model.tflite'  # Replace with your model's path\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n","\n","# Allocate tensors (this will initialize the interpreter and load the model)\n","interpreter.allocate_tensors()\n","\n","# Get input and output details\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Get the shape of the input tensor\n","input_shape = input_details[0]['shape']\n","input_dtype = input_details[0]['dtype']\n","\n","# Load test data (assuming load_mnist function exists)\n","test_images, test_labels = load_mnist(6)\n","\n","# Choose an image from the test set\n","image = test_images  # First image (28x28)\n","label = test_labels  # Ground truth label\n","\n","# Ensure the image has the correct dtype (uint8 for quantized models)\n","image = image.astype(input_dtype)\n","\n","# Set the input tensor\n","interpreter.set_tensor(input_details[0]['index'], image)\n","\n","# Measure inference time\n","start_time = time.time()  # Start timer\n","interpreter.invoke()       # Run inference\n","end_time = time.time()     # End timer\n","\n","# Compute elapsed time\n","inference_time = (end_time - start_time) * 1000  # Convert to milliseconds\n","\n","# Get the output tensor\n","output_data = interpreter.get_tensor(output_details[0]['index'])\n","\n","# Normalize the output data if needed\n","output_data = output_data.astype('float32') / 256.0\n","\n","# Apply softmax if necessary\n","probabilities = tf.nn.softmax(output_data[0]).numpy()\n","\n","# Print raw output and predicted class\n","print(\"Raw Model Output (Logits):\")\n","print(output_data[0])\n","\n","predicted_class = np.argmax(probabilities)\n","\n","print(f\"Predicted Class: {predicted_class}\")\n","print(f\"Ground Truth Label: {label}\")\n","\n","# Print inference time\n","print(f\"Inference Time: {inference_time:.2f} ms\")\n"],"metadata":{"id":"sGgbd8un7WkH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740387507261,"user_tz":-120,"elapsed":462,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}},"outputId":"98ad9695-5c9d-4fb5-9bc9-72e526131535"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Raw Model Output (Logits):\n","[0.         0.         0.         0.         0.984375   0.\n"," 0.         0.0078125  0.00390625 0.00390625]\n","Predicted Class: 4\n","Ground Truth Label: 4\n","Inference Time: 0.28 ms\n"]}]},{"cell_type":"code","source":["#quantized gia 10 input\n","import time\n","import numpy as np\n","import tensorflow as tf\n","\n","# Load the TFLite model\n","tflite_model_path = 'quantized_model.tflite'  # Replace with your model's path\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n","\n","# Allocate tensors (this will initialize the interpreter and load the model)\n","interpreter.allocate_tensors()\n","\n","# Get input and output details\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Get the shape and dtype of the input tensor\n","input_shape = input_details[0]['shape']\n","input_dtype = input_details[0]['dtype']\n","\n","# Load test data\n","for i in range (1,11):\n","  test_images, test_labels = load_mnist(i)  # Ensure load_mnist is defined\n","  image = test_images  # Select first image\n","  label = test_labels  # Corresponding label\n","\n","# Set the input tensor\n","  interpreter.set_tensor(input_details[0]['index'], image)\n","\n","# Measure inference time\n","  start_time = time.time()  # Start timer\n","  interpreter.invoke()       # Run inference\n","  end_time = time.time()     # End timer\n","\n","# Compute elapsed time\n","  inference_time += (end_time - start_time) * 1000  # Convert to milliseconds\n","\n","# Get the output tensor\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","\n","# Normalize the output data\n","  output_data = output_data.astype('float32') / 256.0\n","\n","# Apply softmax to get probabilities\n","  probabilities = tf.nn.softmax(output_data[0]).numpy()\n","\n","# Print raw output and predicted class\n","  #print(\"Raw Model Output (Logits):\")\n","  #print(output_data[0])\n","\n","  predicted_class = np.argmax(probabilities)\n","  print(f\"Predicted Class: {predicted_class}\")\n","  print(f\"Ground Truth Label: {label}\")\n","\n","# Print inference time\n","print(f\"Inference Time: {inference_time/(i):.2f} ms\")"],"metadata":{"id":"TDUuhNbjbFzx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740387510622,"user_tz":-120,"elapsed":3362,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}},"outputId":"e7c7bbe3-05ac-4542-f7b1-0d13b0eb358f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Class: 2\n","Ground Truth Label: 2\n","Predicted Class: 1\n","Ground Truth Label: 1\n","Predicted Class: 0\n","Ground Truth Label: 0\n","Predicted Class: 4\n","Ground Truth Label: 4\n","Predicted Class: 1\n","Ground Truth Label: 1\n","Predicted Class: 4\n","Ground Truth Label: 4\n","Predicted Class: 9\n","Ground Truth Label: 9\n","Predicted Class: 5\n","Ground Truth Label: 5\n","Predicted Class: 9\n","Ground Truth Label: 9\n","Predicted Class: 0\n","Ground Truth Label: 0\n","Inference Time: 0.16 ms\n"]}]},{"cell_type":"code","source":["#aplo gia 10 input\n","#RUN MODEL\n","import time\n","import numpy as np\n","import tensorflow as tf\n","\n","# Load the TFLite model\n","tflite_model_path = 'model.tflite'  # Replace with your model's path\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n","\n","# Allocate tensors (this will initialize the interpreter and load the model)\n","interpreter.allocate_tensors()\n","\n","# Get input and output details\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Get the shape and dtype of the input tensor\n","input_shape = input_details[0]['shape']\n","input_dtype = input_details[0]['dtype']\n","inference_time = 0\n","\n","# Load test data (assuming load_mnist function exists)\n","for i in range (1,10):\n","  test_images, test_labels = load_mnist(i)  # Ensure load_mnist is defined\n","  image = test_images.astype(np.float32) / 255.0  # Normalize to [0,1] for float32 model\n","  label = test_labels  # Corresponding label\n","\n","# Ensure input tensor has the correct shape and type\n","  image = np.reshape(image, input_shape).astype(np.float32)  # Explicitly cast to float32\n","\n","# Set the input tensor\n","  interpreter.set_tensor(input_details[0]['index'], image)\n","\n","# Measure inference time\n","  start_time = time.time()  # Start timer\n","  interpreter.invoke()       # Run inference\n","  end_time = time.time()     # End timer\n","\n","  # Compute elapsed time\n","  inference_time += (end_time - start_time) * 1000  # Convert to milliseconds\n","\n","# Get the output tensor\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","\n","# Apply softmax to get probabilities\n","  probabilities = tf.nn.softmax(output_data[0]).numpy()\n","\n","# Print raw output and predicted class\n","  #print(\"Raw Model Output (Logits):\")\n","  #print(output_data[0])\n","\n","  predicted_class = np.argmax(probabilities)\n","  print(f\"Predicted Class: {predicted_class}\")\n","  print(f\"Ground Truth Label: {label}\")\n","\n","# Print inference time\n","print(f\"Inference Time: {inference_time/(i):.2f} ms\")"],"metadata":{"id":"cHHpVoDF2bwG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740387513593,"user_tz":-120,"elapsed":2970,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}},"outputId":"93a004bf-87e2-49dd-de4b-c22ac699ec14"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Class: 2\n","Ground Truth Label: 2\n","Predicted Class: 1\n","Ground Truth Label: 1\n","Predicted Class: 0\n","Ground Truth Label: 0\n","Predicted Class: 4\n","Ground Truth Label: 4\n","Predicted Class: 1\n","Ground Truth Label: 1\n","Predicted Class: 4\n","Ground Truth Label: 4\n","Predicted Class: 9\n","Ground Truth Label: 9\n","Predicted Class: 5\n","Ground Truth Label: 5\n","Predicted Class: 9\n","Ground Truth Label: 9\n","Inference Time: 0.12 ms\n"]}]},{"cell_type":"code","source":["#aplo gia 1 input\n","#RUN MODEL\n","import time\n","import numpy as np\n","import tensorflow as tf\n","\n","# Load the TFLite model\n","tflite_model_path = 'model.tflite'  # Replace with your model's path\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n","\n","# Allocate tensors (this will initialize the interpreter and load the model)\n","interpreter.allocate_tensors()\n","\n","# Get input and output details\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Get the shape and dtype of the input tensor\n","input_shape = input_details[0]['shape']\n","input_dtype = input_details[0]['dtype']\n","inference_time = 0\n","\n","# Load test data (assuming load_mnist function exists)\n","\n","test_images, test_labels = load_mnist(1)  # Ensure load_mnist is defined\n","image = test_images.astype(np.float32) / 255.0  # Normalize to [0,1] for float32 model\n","label = test_labels  # Corresponding label\n","\n","# Ensure input tensor has the correct shape and type\n","image = np.reshape(image, input_shape).astype(np.float32)  # Explicitly cast to float32\n","\n","# Set the input tensor\n","interpreter.set_tensor(input_details[0]['index'], image)\n","\n","# Measure inference time\n","start_time = time.time()  # Start timer\n","interpreter.invoke()       # Run inference\n","end_time = time.time()     # End timer\n","\n","# Compute elapsed time\n","inference_time += (end_time - start_time) * 1000  # Convert to milliseconds\n","\n","# Get the output tensor\n","output_data = interpreter.get_tensor(output_details[0]['index'])\n","\n","# Apply softmax to get probabilities\n","probabilities = tf.nn.softmax(output_data[0]).numpy()\n","\n","# Print raw output and predicted class\n","#print(\"Raw Model Output (Logits):\")\n","#print(output_data[0])\n","\n","predicted_class = np.argmax(probabilities)\n","print(f\"Predicted Class: {predicted_class}\")\n","print(f\"Ground Truth Label: {label}\")\n","\n","# Print inference time\n","print(f\"Inference Time: {inference_time:.2f} ms\")"],"metadata":{"id":"7QTzKFX-fZoC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740387513926,"user_tz":-120,"elapsed":327,"user":{"displayName":"Χάρης Σπυρόπουλος","userId":"12397977491261589876"}},"outputId":"83354e8f-cd47-4d94-d860-bf931f2e6cbb"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Class: 2\n","Ground Truth Label: 2\n","Inference Time: 0.18 ms\n"]}]}]}