{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Necessary imports"
      ],
      "metadata": {
        "id": "zmojdTjnnKD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEkj768D3uhR",
        "outputId": "2a297f0a-b00e-4176-cf97-fdcedec7e882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.26.4)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.17.2)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G2EiFI_nFkI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # function to create lenet model\n",
        "# def build_lenet5_mnist():\n",
        "\n",
        "\n",
        "#     model = tf.keras.Sequential([\n",
        "\n",
        "#         # 4 layers -> 2 convolutional and 2 pooling\n",
        "#         tf.keras.layers.Conv2D(6, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu', input_shape = (28, 28, 1)),\n",
        "#         tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2),\n",
        "\n",
        "#         tf.keras.layers.Conv2D(16, kernel_size = 5, strides = 1, activation = 'relu'),\n",
        "#         tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2),\n",
        "\n",
        "#         # 2D -> 1D\n",
        "#         tf.keras.layers.Flatten(),\n",
        "\n",
        "#         # 3 fully connected layers\n",
        "#         tf.keras.layers.Dense(120, activation = 'relu'),\n",
        "#         tf.keras.layers.Dense(84, activation = 'relu'),\n",
        "#         tf.keras.layers.Dense(10, activation = 'softmax')\n",
        "#     ])\n",
        "\n",
        "#     return model"
      ],
      "metadata": {
        "id": "KG-iYCZFnP8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a pruning schedule\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "def build_lenet5_mnist_with_pruning():\n",
        "    # Define an even more aggressive pruning schedule (up to 98% sparsity over 6000 steps)\n",
        "    pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n",
        "        initial_sparsity=0.0,  # Start with no pruning\n",
        "        final_sparsity=0.98,   # Increase final sparsity to 98%\n",
        "        begin_step=0,          # Start pruning immediately\n",
        "        end_step=6000          # Extend pruning to 6000 steps\n",
        "    )\n",
        "\n",
        "    # Build model with extreme pruning applied\n",
        "    model = tf.keras.Sequential([\n",
        "        # More aggressively pruned Conv2D Layer\n",
        "        tfmot.sparsity.keras.prune_low_magnitude(\n",
        "            tf.keras.layers.Conv2D(6, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "            pruning_schedule=pruning_schedule\n",
        "        ),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "\n",
        "        # More aggressively pruned Conv2D Layer\n",
        "        tfmot.sparsity.keras.prune_low_magnitude(\n",
        "            tf.keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='relu'),\n",
        "            pruning_schedule=pruning_schedule\n",
        "        ),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "\n",
        "        # Flatten Layer (not pruned)\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        # Extremely pruned Dense Layers\n",
        "        tfmot.sparsity.keras.prune_low_magnitude(\n",
        "            tf.keras.layers.Dense(120, activation='relu'),\n",
        "            pruning_schedule=pruning_schedule\n",
        "        ),\n",
        "        tfmot.sparsity.keras.prune_low_magnitude(\n",
        "            tf.keras.layers.Dense(84, activation='relu'),\n",
        "            pruning_schedule=pruning_schedule\n",
        "        ),\n",
        "\n",
        "        # Output Layer (No Pruning Applied)\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "G_0dqUHy3X3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_for_pruning(validation_split=0.25):\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Normalize images to [0,1] and convert to float32\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # Reshape from (28, 28) to (28, 28, 1) to match CNN input format\n",
        "    x_train = x_train[..., tf.newaxis]\n",
        "    x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "    # **Keep labels as integers** (NOT one-hot encoded) for sparse_categorical_crossentropy\n",
        "    y_train = y_train.astype(np.int32)\n",
        "    y_test = y_test.astype(np.int32)\n",
        "\n",
        "    # Create validation set from training data\n",
        "    if validation_split is not None:\n",
        "        num_validation_samples = int(validation_split * x_train.shape[0])\n",
        "        x_train, x_val = x_train[:-num_validation_samples], x_train[-num_validation_samples:]\n",
        "        y_train, y_val = y_train[:-num_validation_samples], y_train[-num_validation_samples:]\n",
        "        return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
        "\n",
        "    else:\n",
        "        return (x_train, y_train), (x_test, y_test), (x_test, y_test)\n"
      ],
      "metadata": {
        "id": "-P7dUEinCJMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to load MNIST dataset and do some preprocessing\n",
        "def load_data(validation_split = 0.25):\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Normalization can reduce training time significantly and (usually) increases the model's accuracy\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # expand dimensions from (28, 28) to (28, 28, 1) to match the input format of the first convolutional layer of the model\n",
        "    x_train = x_train[..., tf.newaxis]\n",
        "    x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "    # Make sure that your labels are in numerical form\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "    # A subset of the dataset can be used in order to monitor how our network behaves during training\n",
        "    # (validation dataset) and helps us avoid overfitting the model to the training dataset.\n",
        "    # The network's parameters are not updated when examining this subset of data\n",
        "\n",
        "    # create validation dataset\n",
        "    if validation_split is not None:\n",
        "        num_validation_samples = int(validation_split * x_train.shape[0])\n",
        "        x_train, x_val = x_train[:-num_validation_samples], x_train[-num_validation_samples:]\n",
        "        y_train, y_val = y_train[:-num_validation_samples], y_train[-num_validation_samples:]\n",
        "        return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
        "\n",
        "    else:\n",
        "        return (x_train, y_train), (x_test, y_test), (x_test, y_test)"
      ],
      "metadata": {
        "id": "m0p62a1Zpibz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs = 25, learning_rate = 0.001,\n",
        "                patience = 5, batch_size = 32):\n",
        "\n",
        "    # You can experiment with different optimizers and learning rates (no need to focus on that though !!!)\n",
        "    model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = learning_rate, momentum = 0.9),\n",
        "                  loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    # Apply early stopping to speed up training and avoid overfitting (very helpful with smaller datasets)\n",
        "    # In this instance, if the validation loss does not drop over 0.001 for <patience> number of epochs,\n",
        "    # the training stops.\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = patience,\n",
        "                                   min_delta = 0.001, restore_best_weights = True)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size,\n",
        "              validation_data = (X_val, y_val),\n",
        "              callbacks = [early_stopping])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "pApUGVgUqIvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_prune_model(model, X_train, y_train, X_val, y_val, epochs=25, learning_rate=0.001, patience=5, batch_size=32):\n",
        "    # Compile the model (ensure pruning is applied)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Show model summary to verify pruning is applied\n",
        "    model.summary()\n",
        "\n",
        "    # Define pruning callbacks\n",
        "    pruning_callbacks = [\n",
        "        tfmot.sparsity.keras.UpdatePruningStep(),  # Ensures pruning is updated during training\n",
        "        tfmot.sparsity.keras.PruningSummaries(log_dir='./pruning_logs'),  # Logs pruning progress\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)  # Prevents overfitting\n",
        "    ]\n",
        "\n",
        "    # Train model (pruning is applied dynamically)\n",
        "    model.fit(X_train, y_train,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(X_val, y_val),\n",
        "              callbacks=pruning_callbacks)\n",
        "\n",
        "    return model  # Return trained model\n"
      ],
      "metadata": {
        "id": "-olOyYbd4Brv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g1izn1Ms3Huc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to evaluate the accuracy of the trained model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    _, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "    return test_accuracy * 100"
      ],
      "metadata": {
        "id": "byhIb8rgrR-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to provide a small dataset sample for integer quantization\n",
        "def representative_dataset():\n",
        "    \"\"\"\"\n",
        "    Representative dataset for integer quantization (calibration data to scale the\n",
        "    weights and inputs to the integer domain)\n",
        "    \"\"\"\n",
        "    for i in range(100):\n",
        "        yield [X_train[i:i+1].astype('float32')]"
      ],
      "metadata": {
        "id": "za0psVTlrlqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to cnvert the model to TFLite format (to use in our device)\n",
        "def convert_to_tflite(model, filename = \"pruned_model.tflite\"):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"Model converted to TFLite and saved as {filename}\")\n",
        "\n",
        "    model_size = os.path.getsize(filename) / 1024  # Size in KB\n",
        "    print(f\"TFLite Model Size: {model_size:.2f} KB\")\n",
        "\n",
        "    return filename\n"
      ],
      "metadata": {
        "id": "PYZU3ijzsU3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a representative dataset for quantization\n",
        "def representative_dataset():\n",
        "    for _ in range(100):  # Use a small batch of 100 samples\n",
        "        data = np.random.rand(1, 28, 28, 1).astype(np.float32)  # Match model input shape\n",
        "        yield [data]\n",
        "\n",
        "# Convert a pruned model to a quantized TFLite model\n",
        "def convert_to_quantized_tflite(model, filename=\"pruned_model.tflite\"):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "    # Enable post-training quantization\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "    # Set a representative dataset for better quantization accuracy\n",
        "    converter.representative_dataset = representative_dataset\n",
        "\n",
        "    # Enforce full integer quantization\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.int8  # Use int8 instead of uint8\n",
        "    converter.inference_output_type = tf.int8\n",
        "\n",
        "    # Convert the model\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the quantized model\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(f\" Quantized model saved as {filename}\")\n",
        "\n",
        "    # Print model size\n",
        "    model_size = os.path.getsize(filename) / 1024  # Convert bytes to KB\n",
        "    print(f\" Quantized Model Size: {model_size:.2f} KB\")\n",
        "\n",
        "    return filename"
      ],
      "metadata": {
        "id": "aRXDF7hdslmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to perform inference for a tflite model\n",
        "def tflite_inference(tflite_model_path, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Perform inference using a quantized TFLite model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the TFLite model\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output details\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Get input and output dtype (for quantized model, should be int8)\n",
        "    input_dtype = input_details[0]['dtype']\n",
        "    output_dtype = output_details[0]['dtype']\n",
        "    print(f\"Input dtype: {input_dtype}, Output dtype: {output_dtype}\")\n",
        "\n",
        "    # Fix: Handle both int8 and uint8 quantization formats\n",
        "    if input_dtype in [np.uint8, np.int8]:\n",
        "        input_scale, input_zero_point = input_details[0]['quantization']\n",
        "        X_test = (X_test / input_scale + input_zero_point).astype(input_dtype)\n",
        "\n",
        "    correct = 0\n",
        "    total = X_test.shape[0]\n",
        "\n",
        "    # Run inference on all test samples\n",
        "    for i in range(total):\n",
        "        input_data = X_test[i:i+1]  # Select one sample\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()  # Run inference\n",
        "\n",
        "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "        # Fix: Dequantize output if necessary\n",
        "        if output_dtype in [np.uint8, np.int8]:\n",
        "            output_scale, output_zero_point = output_details[0]['quantization']\n",
        "            output_data = (output_data.astype(np.float32) - output_zero_point) * output_scale\n",
        "\n",
        "        # Apply softmax & get predicted label\n",
        "        probabilities = tf.nn.softmax(output_data[0]).numpy()\n",
        "        predicted_label = np.argmax(probabilities)\n",
        "\n",
        "        # Fix: Check if y_test is one-hot encoded or categorical\n",
        "        if len(y_test.shape) > 1:  # One-hot encoded\n",
        "            true_label = np.argmax(y_test[i])\n",
        "        else:  # Already categorical\n",
        "            true_label = y_test[i]\n",
        "\n",
        "        if predicted_label == true_label:\n",
        "            correct += 1\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = (correct / total) * 100\n",
        "    print(f\"TFLite Model Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "BOlwle93tfSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify device (CPU or GPU)\n",
        "device_name = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "print(f\"Training on: {device_name}\")\n",
        "\n",
        "with tf.device(device_name):\n",
        "\n",
        "    # lenet model\n",
        "    pruned_model = build_lenet5_mnist_with_pruning()\n",
        "    pruned_model.summary()\n",
        "\n",
        "    epochs = [1, 1]\n",
        "    learning_rate = [0.001, 0.0005]\n",
        "    BATCH_SZ = 32\n",
        "    patience = 3\n",
        "\n",
        "    # load mnist\n",
        "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_data_for_pruning()\n",
        "\n",
        "    # perform training\n",
        "    for i, (e, lr) in enumerate(zip(epochs, learning_rate)):\n",
        "        print(f\"\\nStarting training iteration {i + 1} with {e} epochs and learning rate {lr}\")\n",
        "        pruned_model = train_prune_model(pruned_model, X_train, y_train, X_val, y_val, e, lr, patience, BATCH_SZ)\n",
        "\n",
        "    print(\"\\n\\nFinal Evaluation on Test Data:\")\n",
        "    pruned1_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "    # Recompile the model (Use the same loss and optimizer as before)\n",
        "    pruned1_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    initial_model_accuracy = evaluate_model(pruned1_model, X_test, y_test)\n",
        "\n",
        "    ########## Let's convert the model to TFLITE FORMAT ###########\n",
        "    tflite_model_path = convert_to_tflite(pruned1_model)\n",
        "\n",
        "    # Without applying any optimizations to our model, the accuracy should remain the same ...\n",
        "    print(\"\\n\\nPerforming inference with TFLite model...\")\n",
        "    tflite_no_opt_accuracy = tflite_inference(tflite_model_path, X_test, y_test)\n",
        "\n",
        "    ##### QUANTIZATION #####\n",
        "\n",
        "    # integer_tflite_path = convert_to_quantized_tflite(model, filename = \"quantized_model.tflite\")\n",
        "\n",
        "    # print(f\"\\nInference with Integer quantization...\")\n",
        "    # tflite_int_quant_acc = tflite_inference(integer_tflite_path, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x7MBLoAubSv",
        "outputId": "6054f6a0-787e-45c0-88c3-74170d282aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on: /GPU:0\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 28, 28, 6)         308       \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 6)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 10, 10, 16)        4818      \n",
            " _1 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense   (None, 120)               96122     \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 84)                20246     \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122344 (477.92 KB)\n",
            "Trainable params: 61706 (241.04 KB)\n",
            "Non-trainable params: 60638 (236.88 KB)\n",
            "_________________________________________________________________\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "\n",
            "Starting training iteration 1 with 1 epochs and learning rate 0.001\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 28, 28, 6)         308       \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 6)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 10, 10, 16)        4818      \n",
            " _1 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense   (None, 120)               96122     \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 84)                20246     \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122344 (477.92 KB)\n",
            "Trainable params: 61706 (241.04 KB)\n",
            "Non-trainable params: 60638 (236.88 KB)\n",
            "_________________________________________________________________\n",
            "   1/1407 [..............................] - ETA: 4:27:00 - loss: 2.3097 - accuracy: 0.1875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0047s vs `on_train_batch_end` time: 0.0055s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 27s 11ms/step - loss: 0.2100 - accuracy: 0.9362 - val_loss: 0.0981 - val_accuracy: 0.9703\n",
            "\n",
            "Starting training iteration 2 with 1 epochs and learning rate 0.0005\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 28, 28, 6)         308       \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 6)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 10, 10, 16)        4818      \n",
            " _1 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense   (None, 120)               96122     \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 84)                20246     \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122344 (477.92 KB)\n",
            "Trainable params: 61706 (241.04 KB)\n",
            "Non-trainable params: 60638 (236.88 KB)\n",
            "_________________________________________________________________\n",
            "1407/1407 [==============================] - 13s 7ms/step - loss: 0.0785 - accuracy: 0.9772 - val_loss: 0.1009 - val_accuracy: 0.9699\n",
            "\n",
            "\n",
            "Final Evaluation on Test Data:\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.9744\n",
            "Test Accuracy: 97.44%\n",
            "Model converted to TFLite and saved as pruned_model.tflite\n",
            "TFLite Model Size: 244.73 KB\n",
            "\n",
            "\n",
            "Performing inference with TFLite model...\n",
            "Input dtype: <class 'numpy.float32'>, Output dtype: <class 'numpy.float32'>\n",
            "TFLite Model Accuracy: 97.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist(i = 0):\n",
        "    # Load MNIST dataset\n",
        "    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Normalize the images to be between 0 and 1\n",
        "    # comment below for the quantized\n",
        "    # train_images = train_images.astype('float32') / 255.0\n",
        "    # test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "    # Reshape the images to add the channel dimension (28, 28, 1)\n",
        "    train_images = np.expand_dims(train_images, axis=-1)  # (28, 28, 1)\n",
        "    test_images = np.expand_dims(test_images, axis=-1)  # (28, 28, 1)\n",
        "\n",
        "    # Return a single image with the batch dimension (1, 28, 28, 1)\n",
        "    # Adding the batch dimension for a single image from the test set\n",
        "    return np.expand_dims(test_images[i], axis=0), test_labels[i]  # Shape will be (1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "MXGV7AT9LUBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#RUN MODEL\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model\n",
        "tflite_model_path = 'pruned_model.tflite'  # Replace with your model's path\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "\n",
        "# Allocate tensors (this will initialize the interpreter and load the model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Get the shape and dtype of the input tensor\n",
        "input_shape = input_details[0]['shape']\n",
        "input_dtype = input_details[0]['dtype']\n",
        "inference_time = 0\n",
        "\n",
        "# Load test data (assuming load_mnist function exists)\n",
        "#for i in range (1,20):\n",
        "test_images, test_labels = load_mnist(1)  # Ensure load_mnist is defined\n",
        "image = test_images.astype(np.float32) / 255.0  # Normalize to [0,1] for float32 model\n",
        "label = test_labels  # Corresponding label\n",
        "\n",
        "# Ensure input tensor has the correct shape and type\n",
        "image = np.reshape(image, input_shape).astype(np.float32)  # Explicitly cast to float32\n",
        "\n",
        "# Set the input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], image)\n",
        "\n",
        "# Measure inference time\n",
        "start_time = time.time()  # Start timer\n",
        "interpreter.invoke()       # Run inference\n",
        "end_time = time.time()     # End timer\n",
        "\n",
        "# Compute elapsed time\n",
        "inference_time += (end_time - start_time) * 1000  # Convert to milliseconds\n",
        "\n",
        "# Get the output tensor\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "# Apply softmax to get probabilities\n",
        "probabilities = tf.nn.softmax(output_data[0]).numpy()\n",
        "\n",
        "# Print raw output and predicted class\n",
        "#print(\"Raw Model Output (Logits):\")\n",
        "#print(output_data[0])\n",
        "\n",
        "predicted_class = np.argmax(probabilities)\n",
        "print(f\"Predicted Class: {predicted_class}\")\n",
        "print(f\"Ground Truth Label: {label}\")\n",
        "\n",
        "# Print inference time\n",
        "print(f\"Inference Time: {inference_time/1:.2f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHHpVoDF2bwG",
        "outputId": "c0285fd0-cc01-4a7e-8fec-d18618594ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 2\n",
            "Ground Truth Label: 2\n",
            "Inference Time: 0.18 ms\n"
          ]
        }
      ]
    }
  ]
}